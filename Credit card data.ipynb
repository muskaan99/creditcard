{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d63eca8",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection using SVM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01686858",
   "metadata": {},
   "source": [
    "The dataset is obtained from https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace565d3",
   "metadata": {},
   "source": [
    "The dataset comprises of Time, Amount, Class and 28 features(V1 to V28) obtained from PCA. Support vector machines (SVM) will be used for classification. We will make use of the features and Class in classification by using different kernel functions. Linear Kernel, RBF Kernel, Sigmoid Kernel and Polynomial Kernel are the four different types of kernel functions which were tried out.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e005a5e",
   "metadata": {},
   "source": [
    "The dataset contains only 0.172% of fraud cases so it is very unbalanced. The dataset is split as 70% training data and 30% testing data. As the dataset is unbalanced we train the model on 50-50 data of fraud and non fraud cases instead of a highly biased dataset towards non fraud cases. This helps the model to learn better about the fraud cases.  We test the models using the same method of 50% fraud cases and 50% non fraudd cases from the test data. This new test data is better to use as compared to the old test data where the non fraud cases were extremely high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e34a420",
   "metadata": {},
   "source": [
    "## Steps:\n",
    "1. Reading and visualising the data\n",
    "2. Preparing the data for modeling\n",
    "3. Build and train the model on new_Xtrain and new_ytrain and evaluate the model on accuracy and f1 score for different kernels using new_Xtest and new_ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d85dff7",
   "metadata": {},
   "source": [
    "### Reading and visualising the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4c208e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37c7c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36f7a16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (284807, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load dataset\n",
    "dt=pd.read_csv(r'C:\\Users\\muska\\Documents\\svm\\credit_card.csv')\n",
    "print('Shape of dataset:',dt.shape)\n",
    "dt.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbcb86de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatypes of dataset\n",
      "\n",
      "Time      float64\n",
      "V1        float64\n",
      "V2        float64\n",
      "V3        float64\n",
      "V4        float64\n",
      "V5        float64\n",
      "V6        float64\n",
      "V7        float64\n",
      "V8        float64\n",
      "V9        float64\n",
      "V10       float64\n",
      "V11       float64\n",
      "V12       float64\n",
      "V13       float64\n",
      "V14       float64\n",
      "V15       float64\n",
      "V16       float64\n",
      "V17       float64\n",
      "V18       float64\n",
      "V19       float64\n",
      "V20       float64\n",
      "V21       float64\n",
      "V22       float64\n",
      "V23       float64\n",
      "V24       float64\n",
      "V25       float64\n",
      "V26       float64\n",
      "V27       float64\n",
      "V28       float64\n",
      "Amount    float64\n",
      "Class       int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('Datatypes of dataset\\n')\n",
    "print(dt.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09728484",
   "metadata": {},
   "source": [
    "The datatype of all the features from V1 to V28 is same i.e. float64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53330ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3919fb23",
   "metadata": {},
   "source": [
    "We can observe that the dataset comprising of total 284807 entries out of which it has only 492 entries for fraud which makes the dataset very unbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485d3a99",
   "metadata": {},
   "source": [
    "### Preparing the data for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bf95d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=dt.loc[:,\"V1\":\"V28\"]#extracting features\n",
    "X=np.asarray(features)\n",
    "y=np.asarray(dt['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3555ea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset into 30% test and 70% train\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e401669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (199364, 28)\n",
      "Shape of y_train: (199364,)\n",
      "Shape of X_test: (85443, 28)\n",
      "Shape of y_test: (85443,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X_train:',X_train.shape)\n",
    "print('Shape of y_train:',y_train.shape)\n",
    "print('Shape of X_test:',X_test.shape)\n",
    "print('Shape of y_test:',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80306889",
   "metadata": {},
   "source": [
    "As the dataset is highly unbalanced, we split the training data as per the number of frauds in y_train. This allows us to have 50-50 data of fraud and non fraud cases for training instead of a highly biased dataset towards non fraud cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d5da622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train1: (364,)\n",
      "Shape of X_train1: (364, 28)\n"
     ]
    }
   ],
   "source": [
    "t = np.where(y_train== 1)# reading indices of y_train where there are fraud cases\n",
    "t1=np.asarray(t)\n",
    "for i,index in enumerate(t1):\n",
    "    y_train1=np.asarray(y_train[index][:])\n",
    "len_y_train1=y_train1.size#storing the number of fraud cases found in y_train so that we can pick up the same number of non fraud cases later\n",
    "for i,index in enumerate(t1):\n",
    "    X_train1=np.asarray(X_train[index][:])# reading entries of X_train for fraud cases\n",
    "#number of rows for y_train1 and X_train1 should be same\n",
    "print('Shape of y_train1:',y_train1.shape)\n",
    "print('Shape of X_train1:',X_train1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9af22029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train2: (364,)\n",
      "Shape of X_train2: (364, 28)\n"
     ]
    }
   ],
   "source": [
    "p = np.where(y_train== 0)# reading indices of y_train where there are fraud cases\n",
    "t2=np.random.choice(p[0],size=len_y_train1).reshape(-1,1).T\n",
    "for i,index in enumerate(t2):\n",
    "    y_train2=np.asarray(y_train[index][:])\n",
    "for i,index in enumerate(t2):\n",
    "    X_train2=np.asarray(X_train[index][:])\n",
    "#number of rows for y_train2 and X_train2 should be same\n",
    "print('Shape of y_train2:',y_train2.shape)\n",
    "print('Shape of X_train2:',X_train2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a44edad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of new_ytrain: (728,)\n",
      "Shape of new_Xtrain: (728, 28)\n"
     ]
    }
   ],
   "source": [
    "new_ytrain=np.append(y_train1,y_train2)#concatenate y_train1 and y_train2\n",
    "new_Xtrain=np.concatenate((X_train1,X_train2),axis=0)#concatenate X_train1 and X_train2\n",
    "new_Xtrain.shape\n",
    "print('Shape of new_ytrain:',new_ytrain.shape)\n",
    "print('Shape of new_Xtrain:',new_Xtrain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95508a85",
   "metadata": {},
   "source": [
    "new_ytrain and new_Xtrain are the new training sets we will use for training our models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f140b27",
   "metadata": {},
   "source": [
    "Similarly, we will change the testing sets as they are also unbalanced.Thus, we will have 50-50 data of fraud and non fraud cases for testing the models instead of a highly biased dataset towards non fraud cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8948cd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_test1: (128,)\n",
      "Shape of X_test1: (128, 28)\n"
     ]
    }
   ],
   "source": [
    "j = np.where(y_test == 1)# reading indices of y_test where there are fraud cases\n",
    "t3=np.asarray(j)\n",
    "for i,index in enumerate(t3):\n",
    "    y_test1=np.asarray(y_test[index][:])\n",
    "len_y_test1=y_test1.size#storing the number of fraud cases found in y_test so that we can pick up the same number of non fraud cases later\n",
    "for i,index in enumerate(t3):\n",
    "    X_test1=np.asarray(X_test[index][:])\n",
    "#number of rows for y_test1 and X_test1 should be same\n",
    "print('Shape of y_test1:',y_test1.shape)\n",
    "print('Shape of X_test1:',X_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb022704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_test2: (128,)\n",
      "Shape of X_test2: (128, 28)\n"
     ]
    }
   ],
   "source": [
    "k = np.where(y_test== 0)# reading indices of y_test where there are non fraud cases\n",
    "t4=np.random.choice(k[0],size=len_y_test1).reshape(-1,1).T\n",
    "for i,index in enumerate(t4):\n",
    "    y_test2=np.asarray(y_test[index][:])\n",
    "for i,index in enumerate(t4):\n",
    "    X_test2=np.asarray(X_test[index][:])\n",
    "#number of rows for y_test2 and X_test2 should be same\n",
    "print('Shape of y_test2:',y_test2.shape)\n",
    "print('Shape of X_test2:',X_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b0cf98f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of new_ytest: (256,)\n",
      "Shape of new_Xtest: (256, 28)\n"
     ]
    }
   ],
   "source": [
    "new_ytest=np.append(y_test1,y_test2)#concatenate y_test1 and y_test2\n",
    "new_Xtest=np.concatenate((X_test1,X_test2),axis=0)#concatenate X_test1 and X_test2\n",
    "print('Shape of new_ytest:',new_ytest.shape)\n",
    "print('Shape of new_Xtest:',new_Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce9f7b2",
   "metadata": {},
   "source": [
    "### Build and train the model on new_Xtrain and new_ytrain and evaluate the model on accuracy and f1 score for different kernels using new_Xtest and new_ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ea35135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Linear Kernel:  94.92\n",
      "F1 Score of Linear Kernel:  94.91\n",
      "Confusion matrix:\n",
      "[[127   1]\n",
      " [ 12 116]]\n"
     ]
    }
   ],
   "source": [
    "#Linear Kernel\n",
    "linear=svm.SVC(kernel='linear',gamma='auto',C=2)\n",
    "linear.fit(new_Xtrain,new_ytrain)\n",
    "linear_predict = linear.predict(new_Xtest)\n",
    "linear_accuracy = accuracy_score(new_ytest, linear_predict)\n",
    "linear_f1 = f1_score(new_ytest, linear_predict, average='weighted')\n",
    "print('Accuracy of Linear Kernel: ', \"%.2f\" % (linear_accuracy*100))\n",
    "print('F1 Score of Linear Kernel: ', \"%.2f\" % (linear_f1*100))\n",
    "cm1 = confusion_matrix(new_ytest, linear_predict)\n",
    "print('Confusion matrix:')\n",
    "print(cm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c674dabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RBF Kernel:  92.97\n",
      "F1 Score of RBF Kernel:  92.93\n",
      "Confusion matrix:\n",
      "[[128   0]\n",
      " [ 18 110]]\n"
     ]
    }
   ],
   "source": [
    "#RBF Kernel\n",
    "rbf = svm.SVC(kernel = 'rbf', random_state = 0)\n",
    "rbf.fit(new_Xtrain,new_ytrain)\n",
    "rbf_predict = rbf.predict(new_Xtest)\n",
    "rbf_accuracy = accuracy_score(new_ytest, rbf_predict)\n",
    "rbf_f1 = f1_score(new_ytest, rbf_predict, average='weighted')\n",
    "print('Accuracy of RBF Kernel: ', \"%.2f\" % (rbf_accuracy*100))\n",
    "print('F1 Score of RBF Kernel: ', \"%.2f\" % (rbf_f1*100))\n",
    "cm2 = confusion_matrix(new_ytest, rbf_predict)\n",
    "print('Confusion matrix:')\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e680d52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Sigmoid Kernel:  90.23\n",
      "F1 Score of Sigmoid Kernel:  90.22\n",
      "Confusion matrix:\n",
      "[[120   8]\n",
      " [ 17 111]]\n"
     ]
    }
   ],
   "source": [
    "#Sigmoid Kernel\n",
    "sigmoid = svm.SVC(kernel='sigmoid', C=1)\n",
    "sigmoid.fit(new_Xtrain,new_ytrain)\n",
    "sigmoid_predict = sigmoid.predict(new_Xtest)\n",
    "sigmoid_accuracy = accuracy_score(new_ytest, sigmoid_predict)\n",
    "sigmoid_f1 = f1_score(new_ytest, sigmoid_predict, average='weighted')\n",
    "print('Accuracy of Sigmoid Kernel: ', \"%.2f\" % (sigmoid_accuracy*100))\n",
    "print('F1 Score of Sigmoid Kernel: ', \"%.2f\" % (sigmoid_f1*100))\n",
    "cm3 = confusion_matrix(new_ytest, sigmoid_predict)\n",
    "print('Confusion matrix:')\n",
    "print(cm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db7cdadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Polynomial Kernel:  87.50\n",
      "F1 Score of Polynomial Kernel:  87.30\n",
      "Confusion matrix:\n",
      "[[128   0]\n",
      " [ 32  96]]\n"
     ]
    }
   ],
   "source": [
    "#Polynomial Kernel\n",
    "poly = svm.SVC(kernel='poly', degree=3, C=1)\n",
    "poly.fit(new_Xtrain,new_ytrain)\n",
    "poly_predict = poly.predict(new_Xtest)\n",
    "poly_accuracy = accuracy_score(new_ytest, poly_predict)\n",
    "poly_f1 = f1_score(new_ytest, poly_predict, average='weighted')\n",
    "print('Accuracy of Polynomial Kernel: ', \"%.2f\" % (poly_accuracy*100))\n",
    "print('F1 Score of Polynomial Kernel: ', \"%.2f\" % (poly_f1*100))\n",
    "cm4 = confusion_matrix(new_ytest, poly_predict)\n",
    "print('Confusion matrix:')\n",
    "print(cm4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7182eb",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966d6063",
   "metadata": {},
   "source": [
    "When we take the case of 50-50 fraud and non fraud cases for both training(new_Xtrain,new_ytrain) and test(new_Xtest,new_ytest) dataset we can see that the f1 score is 94.91 and accuracy is 94.92% for the linear kernel case making it the best performing kernel. The second best performing kernel is the RBF kernel with accuracy 92.97%.\n",
    "In case we use the train(X_train,y_train) and test(X_test,y_test) data set on the model, the model overfits as the datapoints of non fraud cases dominates and the accuracy comes around 99%. Thus, dividing the dataset as 50-50 fraud and non fraud cases for both training and test cases allows the model to learn more about the fraudulent cases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
